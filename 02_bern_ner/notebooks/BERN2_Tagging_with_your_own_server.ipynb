{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwkuVgxtHbgV"
      },
      "source": [
        "# In the name of Allah"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook has been tested in colab. If you want to use this notebook in Colab, it should be Colab Pro and be set to TPU processor and high-ram mode.\n"
      ],
      "metadata": {
        "id": "KX22yr-aPcoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install conda"
      ],
      "metadata": {
        "id": "19h_c1XbMg0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NOwdiSEsHoJM"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vez0oDbcJdid",
        "outputId": "9426d8fe-6160-43c8-8d00-9039d78973ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:22\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addr to BERN2 databases. You must define this in your terminal"
      ],
      "metadata": {
        "id": "gI9d1TKfM5Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BERN2_databases='/content/drive/MyDrive/BIFO/temp/resources_20220112.tar.gz'"
      ],
      "metadata": {
        "id": "VpO9-7v9M79N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addr to uptodate paragraphs zip file"
      ],
      "metadata": {
        "id": "5Nb7IV7pNPMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utd_parag_addr = '/content/drive/MyDrive/BIFO/temp/parag.zip'"
      ],
      "metadata": {
        "id": "idqLpFaPNejx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owte_aDg7WKt",
        "outputId": "fffab90b-4678-42f9-929f-89e1cb8ce0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/BIFO/temp/parag.zip\n",
            "  inflating: parag.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip '$utd_parag_addr'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run these commands in terminal (according to BERN2 github page with some changes)"
      ],
      "metadata": {
        "id": "lPoGYFuCMqh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gPXCG23qINt"
      },
      "outputs": [],
      "source": [
        "conda create -n bern2 python=3.7\n",
        "source activate bern2\n",
        "conda install pytorch==1.9.0 cudatoolkit=10.2 -c pytorch\n",
        "conda install faiss-gpu libfaiss-avx2 -c conda-forge\n",
        "python -c \"import torch;print(torch.cuda.is_available())\"\n",
        "git clone https://github.com/dmis-lab/BERN2.git\n",
        "cd BERN2\n",
        "pip install -r requirements.txt\n",
        "tar -zxvf $BERN2_databases -C .\n",
        "rm -rf resources_20220112.tar.gz\n",
        "cd resources/GNormPlusJava/CRF\n",
        "make clean\n",
        "./configure --prefix=\"$HOME\"\n",
        "make\n",
        "make install\n",
        "cd ../../..\n",
        "export CUDA_VISIBLE_DEVICES=0\n",
        "cd scripts\n",
        "mv /content/main.py /content/BERN2/multi_ner/main.py\n",
        "mv /content/neural_normalizer.py /content/BERN2/normalizers/neural_normalizer.py\n",
        "bash run_bern2.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After successfully running above commands, the server is up and you can contiunue runnig below cells to start annotating the data"
      ],
      "metadata": {
        "id": "paSGbkNqQLjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Package imports"
      ],
      "metadata": {
        "id": "OYuJ5R4PP-Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "a4OZHW93P-4h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addr to pickle file where annotations are going to be saved (or saved before to load and continue annotation)"
      ],
      "metadata": {
        "id": "ffIrc8FxQA79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_pickle_addr = './annots_list.pickle'"
      ],
      "metadata": {
        "id": "ns3oZL59QBlQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addr to pickle file which has a list of papers id to annotate (None to annotate all the papers)"
      ],
      "metadata": {
        "id": "YS5CqPMQQDoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "portion_id_addr = None"
      ],
      "metadata": {
        "id": "Mi-ONj6eQEQo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to query BERN2 server with exception handling."
      ],
      "metadata": {
        "id": "kVsWHH06PxtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_plain(text, url=\"http://localhost:8888/plain\"):\n",
        "    trys = 0\n",
        "    while(True):\n",
        "        try:\n",
        "            return requests.post(url, json={'text': text}).json()\n",
        "        except Exception as e:\n",
        "            print(F\"Error in request: {str(e)}\")\n",
        "            print('Sleep for 1 seconds')\n",
        "            time.sleep(1)\n",
        "            if 'Expecting value' in str(e):\n",
        "                trys += 1\n",
        "                text = re.sub(r'www\\.\\w+\\.\\w+', '', text)\n",
        "            if trys > 10:\n",
        "                return {'annotations':[]}"
      ],
      "metadata": {
        "id": "Y_vMKWK5PprA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main procedure to annotate paragraphs"
      ],
      "metadata": {
        "id": "xePbuJblNNyn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoHefjid4MWN"
      },
      "outputs": [],
      "source": [
        "# Load portion_id file and get papers id which you want to get annotate.\n",
        "# If there is no portion_id file, this means you want to annotate all of the papers\n",
        "if portion_id_addr != None:\n",
        "  if os.path.exists(portion_id_addr):\n",
        "    with open(portion_id_addr, 'rb') as f:\n",
        "        portion_id = pickle.load(f)\n",
        "  else:\n",
        "    portion_id = None\n",
        "else:\n",
        "  portion_id = None\n",
        "\n",
        "# Load previously annotated data\n",
        "if os.path.exists(annot_pickle_addr):\n",
        "    with open(annot_pickle_addr, 'rb') as f:\n",
        "        l = pickle.load(f)\n",
        "else:\n",
        "    l=[]\n",
        "\n",
        "# Get paper ids which processed before\n",
        "proccesed_papers_id=[]\n",
        "for row in l:\n",
        "    if row[0] not in proccesed_papers_id:\n",
        "        proccesed_papers_id.append(row[0])\n",
        "\n",
        "# Load uptodate paragraphs\n",
        "df_iter = pd.read_csv('/content/parag.csv').iterrows()\n",
        "i=0\n",
        "for ind, row in tqdm(df_iter):\n",
        "    paper_id = row['paper_id']\n",
        "    if paper_id in proccesed_papers_id or (portion_id != None and paper_id not in portion_id):\n",
        "        continue\n",
        "    paragraph_id = row['parag_id']\n",
        "\n",
        "    if i>180:\n",
        "        i=0\n",
        "        with open(annot_pickle_addr, 'wb') as f:\n",
        "            pickle.dump(l, f)\n",
        "        print('Sleep for 5 seconds')\n",
        "        time.sleep(5)\n",
        "\n",
        "    # If paragpraph length is less than 5000, query whole paragpraph.\n",
        "    # Else break paragraph into sentences and query text with less than 5000 characters\n",
        "    if len(row['text']) < 5000:\n",
        "        annotations = query_plain(row['text'])['annotations']\n",
        "        i+=1\n",
        "        for annot in annotations:\n",
        "            l.append([paper_id, paragraph_id, annot['mention'],\n",
        "                      annot['id'], annot['obj'], annot['prob'],\n",
        "                      annot['span']['begin'], annot['span']['end']])\n",
        "    else:\n",
        "        sentcs = row['text'].split('.')\n",
        "        query = \"\"\n",
        "        qslen = 0\n",
        "        for sentc in sentcs:\n",
        "            if len(query +'. '+ sentc) < 5000:\n",
        "                query = query + sentc + '. '\n",
        "            else:\n",
        "                annotations = query_plain(query)['annotations']\n",
        "                i += 1\n",
        "                for annot in annotations:\n",
        "                    l.append([paper_id, paragraph_id, annot['mention'],\n",
        "                              annot['id'], annot['obj'], annot['prob'],\n",
        "                              qslen+annot['span']['begin'], qslen+annot['span']['end']])\n",
        "                qslen += len(query)\n",
        "                query = \"\"\n",
        "        else:\n",
        "            if query != \"\":\n",
        "                annotations = query_plain(query)['annotations']\n",
        "                i += 1\n",
        "                query = \"\"\n",
        "                for annot in annotations:\n",
        "                    l.append([paper_id, paragraph_id, annot['mention'],\n",
        "                              annot['id'], annot['obj'], annot['prob'],\n",
        "                              qslen+annot['span']['begin'], qslen+annot['span']['end']])\n",
        "\n",
        "# Last pickle dump\n",
        "with open(annot_pickle_addr, 'wb') as f:\n",
        "    pickle.dump(l, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dataframe from annotations"
      ],
      "metadata": {
        "id": "9QNAcRJxijLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bern_df = pd.DataFrame(l, columns=['paper_id', 'parag_id', 'mention', 'object_id', 'object_type', 'prob', 'begin_ind', 'end_ind'])"
      ],
      "metadata": {
        "id": "1i4rkctUipja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get unique annotations and save it as pickle"
      ],
      "metadata": {
        "id": "9DPtji6ciqej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_mentions = list(pd.unique(bern_df['mention']))\n",
        "\n",
        "with open('all_unique_mentions.pickle', 'wb') as f:\n",
        "    pickle.dump(unique_mentions,f)"
      ],
      "metadata": {
        "id": "RCS9CUbuisHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERN2_Tagging with your own server.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}